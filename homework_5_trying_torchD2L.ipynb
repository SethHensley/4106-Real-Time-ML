{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq3A50RuljXG",
        "outputId": "54d27cc3-c119-4863-e320-1adcde7f63d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: d2l in /usr/local/lib/python3.9/dist-packages (0.17.6)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.9/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: pandas==1.2.4 in /usr/local/lib/python3.9/dist-packages (from d2l) (1.2.4)\n",
            "Requirement already satisfied: matplotlib==3.5.1 in /usr/local/lib/python3.9/dist-packages (from d2l) (3.5.1)\n",
            "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.9/dist-packages (from d2l) (2.25.1)\n",
            "Requirement already satisfied: numpy==1.21.5 in /usr/local/lib/python3.9/dist-packages (from d2l) (1.21.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.9/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter==1.0.0->d2l) (6.4.8)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.9/dist-packages (from jupyter==1.0.0->d2l) (5.4.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (23.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->d2l) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas==1.2.4->d2l) (2022.7.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests==2.25.1->d2l) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests==2.25.1->d2l) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests==2.25.1->d2l) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests==2.25.1->d2l) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.2)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.7.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.14.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.38)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.0.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.9.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.11.2)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.8.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.2.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.3.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.2.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.5.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter==1.0.0->d2l) (21.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.16.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.17.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.2.1)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.3.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (67.6.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (3.2.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2.16.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l\n",
        "\n",
        "\n",
        "import os\n",
        "import collections\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#import inspect\n",
        "import torch.ao.ns._numeric_suite_fx as ns\n",
        "\n"
      ],
      "metadata": {
        "id": "U5CuBW20nzGz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#data = pd.read_csv(\"/content/drive/MyDrive/en-fr.csv\") \n",
        "\n"
      ],
      "metadata": {
        "id": "Cjwa9clwse29"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HyperParameters:\n",
        "    \"\"\"The base class of hyperparameters.\"\"\"\n",
        "    def save_hyperparameters(self, ignore=[]):\n",
        "        \"\"\"Defined in :numref:`sec_oo-design`\"\"\"\n",
        "        raise NotImplemented\n",
        "\n",
        "    def save_hyperparameters(self, ignore=[]):\n",
        "        \"\"\"Save function arguments into class attributes.\n",
        "    \n",
        "        Defined in :numref:`sec_utils`\"\"\"\n",
        "        frame = torch.inspect.currentframe().f_back\n",
        "        _, _, _, local_vars = torch.inspect.getargvalues(frame)\n",
        "        self.hparams = {k:v for k, v in local_vars.items()\n",
        "                        if k not in set(ignore+['self']) and not k.startswith('_')}\n",
        "        for k, v in self.hparams.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataModule(HyperParameters):  \n",
        "    \"\"\"The base class of data.\"\"\"\n",
        "    def __init__(self, root='../data', num_workers=4):\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.get_dataloader(train=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.get_dataloader(train=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ECHjUY55L6xq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(d2l.nn.Module):  \n",
        "    \"\"\"The base class of classification models.\"\"\"\n",
        "    def validation_step(self, batch):\n",
        "        Y_hat = self(*batch[:-1])\n",
        "        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n",
        "        self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)\n",
        "\n",
        "\n",
        "class MTFraEng(DataModule):  \n",
        "    \"\"\"The English-French dataset.\"\"\"\n",
        "    def _download(self):\n",
        "        f = pd.read_csv(\"//content//drive//MyDrive//en-fr.csv\")\n",
        "        f= pd.DataFrame.to_string(f)\n",
        "        return f\n",
        "\n",
        "\n",
        "\n",
        "    def _preprocess(self, text):\n",
        "    # Replace non-breaking space with space\n",
        "              text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
        "    # Insert space between words and punctuation marks\n",
        "              no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '\n",
        "              out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
        "            for i, char in enumerate(text.lower())]\n",
        "              return ''.join(out)\n",
        "\n",
        "\n",
        "    def _tokenize(self, text, max_examples=None):\n",
        "      src, tgt = [], []\n",
        "      for i, line in enumerate(text.split('\\n')):\n",
        "          if max_examples and i > max_examples: break\n",
        "          parts = line.split('\\t')\n",
        "          if len(parts) == 2:\n",
        "            # Skip empty tokens\n",
        "              src.append([t for t in f'{parts[0]} <eos>'.split(' ') if t])\n",
        "              tgt.append([t for t in f'{parts[1]} <eos>'.split(' ') if t])\n",
        "      return src, tgt\n",
        "\n",
        "\n",
        "    def __init__(self, batch_size, num_steps=9, num_train=512, num_val=128):\n",
        "     super(MTFraEng, self).__init__()\n",
        "     self.save_hyperparameters()\n",
        "     self.arrays, self.src_vocab, self.tgt_vocab = self._build_arrays(\n",
        "          self._download())\n",
        "    \n",
        "\n",
        "    def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):\n",
        "        def _build_array(sentences, vocab, is_tgt=False):\n",
        "            pad_or_trim = lambda seq, t: (\n",
        "                seq[:t] if len(seq) > t else seq + ['<pad>'] * (t - len(seq)))\n",
        "            sentences = [pad_or_trim(s, self.num_steps) for s in sentences]\n",
        "            if is_tgt:\n",
        "              sentences = [['<bos>'] + s for s in sentences]\n",
        "            if vocab is None:\n",
        "               vocab = d2l.Vocab(sentences, min_freq=2)\n",
        "            array = torch.tensor([vocab[s] for s in sentences])\n",
        "            valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "            return array, vocab, valid_len\n",
        "        src, tgt = self._tokenize(self._preprocess(raw_text),\n",
        "                              self.num_train + self.num_val)\n",
        "        src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)\n",
        "        tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True)\n",
        "        return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]),\n",
        "            src_vocab, tgt_vocab)\n",
        "        \n",
        "        def get_dataloader(self, train):\n",
        "            idx = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
        "            return self.get_tensorloader(self.arrays, train, idx)\n",
        "            \n",
        "\n",
        "        def build(self, src_sentences, tgt_sentences):\n",
        "            raw_text = '\\n'.join([src + '\\t' + tgt for src, tgt in zip(\n",
        "                src_sentences, tgt_sentences)])\n",
        "            arrays, _, _ = self._build_arrays(\n",
        "                raw_text, self.src_vocab, self.tgt_vocab)\n",
        "            return arrays\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # Later there can be additional arguments (e.g., length excluding padding)\n",
        "    def forward(self, X, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Decoder(nn.Module):  \n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # Later there can be additional arguments (e.g., length excluding padding)\n",
        "    def init_state(self, enc_all_outputs, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class EncoderDecoder(Classifier):  \n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, enc_X, dec_X, *args):\n",
        "        enc_all_outputs = self.encoder(enc_X, *args)\n",
        "        dec_state = self.decoder.init_state(enc_all_outputs, *args)\n",
        "        # Return decoder output only\n",
        "        return self.decoder(dec_X, dec_state)[0]\n",
        "\n",
        "def init_seq2seq(module):  \n",
        "    \"\"\"Initialize weights for Seq2Seq.\"\"\"\n",
        "    if type(module) == nn.Linear:\n",
        "         nn.init.xavier_uniform_(module.weight)\n",
        "    if type(module) == nn.GRU:\n",
        "        for param in module._flat_weights_names:\n",
        "            if \"weight\" in param:\n",
        "                nn.init.xavier_uniform_(module._parameters[param])\n",
        "\n",
        "class Seq2SeqEncoder(d2l.Encoder):  \n",
        "    \"\"\"The RNN encoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = d2l.GRU(embed_size, num_hiddens, num_layers, dropout)\n",
        "        self.apply(init_seq2seq)\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        # X shape: (batch_size, num_steps)\n",
        "        embs = self.embedding(X.t().type(torch.int64))\n",
        "        # embs shape: (num_steps, batch_size, embed_size)\n",
        "        outputs, state = self.rnn(embs)\n",
        "        # outputs shape: (num_steps, batch_size, num_hiddens)\n",
        "        # state shape: (num_layers, batch_size, num_hiddens)\n",
        "        return outputs, state\n",
        "\n",
        "class Seq2SeqDecoder(d2l.Decoder):\n",
        "    \"\"\"The RNN decoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = d2l.GRU(embed_size+num_hiddens, num_hiddens,\n",
        "                           num_layers, dropout)\n",
        "        self.dense = nn.LazyLinear(vocab_size)\n",
        "        self.apply(init_seq2seq)\n",
        "\n",
        "    def init_state(self, enc_all_outputs, *args):\n",
        "        return enc_all_outputs\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        # X shape: (batch_size, num_steps)\n",
        "        # embs shape: (num_steps, batch_size, embed_size)\n",
        "        embs = self.embedding(X.t().type(torch.int32))\n",
        "        enc_output, hidden_state = state\n",
        "        # context shape: (batch_size, num_hiddens)\n",
        "        context = enc_output[-1]\n",
        "        # Broadcast context to (num_steps, batch_size, num_hiddens)\n",
        "        context = context.repeat(embs.shape[0], 1, 1)\n",
        "        # Concat at the feature dimension\n",
        "        embs_and_context = torch.cat((embs, context), -1)\n",
        "        outputs, hidden_state = self.rnn(embs_and_context, hidden_state)\n",
        "        outputs = self.dense(outputs).swapaxes(0, 1)\n",
        "        # outputs shape: (batch_size, num_steps, vocab_size)\n",
        "        # hidden_state shape: (num_layers, batch_size, num_hiddens)\n",
        "        return outputs, [enc_output, hidden_state]\n",
        "\n",
        "class Seq2Seq(d2l.EncoderDecoder):  \n",
        "    \"\"\"The RNN encoder-decoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, encoder, decoder, tgt_pad, lr):\n",
        "        super().__init__(encoder, decoder)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        Y_hat = self(*batch[:-1])\n",
        "        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Adam optimizer is used here\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "    def loss(self, Y_hat, Y):\n",
        "        l = super(Seq2Seq, self).loss(Y_hat, Y, averaged=False)\n",
        "        mask = (Y.reshape(-1) != self.tgt_pad).type(torch.float32)\n",
        "        return (l * mask).sum() / mask.sum()\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "14ODM6IEDonl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = MTFraEng(batch_size=128)\n",
        "embed_size, num_hiddens, num_layers, dropout = 128, 128, 2, 0.2\n",
        "encoder = Seq2SeqEncoder(\n",
        "    len(data.en), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqDecoder(\n",
        "    len(data.fr), embed_size, num_hiddens, num_layers, dropout)\n",
        "model = Seq2Seq(encoder, decoder, tgt_pad=data.fr['<pad>'],\n",
        "                lr=0.005)\n",
        "trainer = d2l.Trainer(max_epochs=30, gradient_clip_val=1, num_gpus=1)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "FM7YE5e04JVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fisHlsn14JKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gi5OZfY4JHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(d2l.Decoder):  \n",
        "    \"\"\"The base attention-based decoder interface.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0):\n",
        "        super().__init__()\n",
        "        self.attention = d2l.AdditiveAttention(num_hiddens, dropout)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(\n",
        "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
        "            dropout=dropout)\n",
        "        self.dense = nn.LazyLinear(vocab_size)\n",
        "        self.apply(d2l.init_seq2seq)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_lens):\n",
        "        # Shape of outputs: (num_steps, batch_size, num_hiddens).\n",
        "        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)\n",
        "        outputs, hidden_state = enc_outputs\n",
        "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        # Shape of enc_outputs: (batch_size, num_steps, num_hiddens).\n",
        "        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)\n",
        "        enc_outputs, hidden_state, enc_valid_lens = state\n",
        "        # Shape of the output X: (num_steps, batch_size, embed_size)\n",
        "        X = self.embedding(X).permute(1, 0, 2)\n",
        "        outputs, self._attention_weights = [], []\n",
        "        for x in X:\n",
        "            # Shape of query: (batch_size, 1, num_hiddens)\n",
        "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
        "            # Shape of context: (batch_size, 1, num_hiddens)\n",
        "            context = self.attention(\n",
        "                query, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "            # Concatenate on the feature dimension\n",
        "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
        "            # Reshape x as (1, batch_size, embed_size + num_hiddens)\n",
        "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
        "            outputs.append(out)\n",
        "            self._attention_weights.append(self.attention.attention_weights)\n",
        "        # After fully connected layer transformation, shape of outputs:\n",
        "        # (num_steps, batch_size, vocab_size)\n",
        "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
        "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
        "                                          enc_valid_lens]\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "Awh5xDvz4I7N"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = d2l.MTFraEng(batch_size=128)\n",
        "embed_size, num_hiddens, num_layers, dropout = 256, 256, 2, 0.2\n",
        "encoder = d2l.Seq2SeqEncoder(\n",
        "    len(data.src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqAttentionDecoder(\n",
        "    len(data.tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "model = d2l.Seq2Seq(encoder, decoder, tgt_pad=data.tgt_vocab['<pad>'],\n",
        "                    lr=0.005)\n",
        "trainer = d2l.Trainer(max_epochs=30, gradient_clip_val=1, num_gpus=1)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "RfR4IUCEtslc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}